{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import rcParams\n",
    "rcParams['text.usetex'] = True\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = ['Times New Roman']\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from torchmetrics import AUROC\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from torchmetrics import F1Score\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import F1Score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "import torchmetrics\n",
    "from torchmetrics import Metric\n",
    "import torchmetrics.classification\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from torchmetrics import Accuracy, MetricCollection, Precision, Recall, F1Score, Metric\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryConfusionMatrix\n",
    "from torch import tensor\n",
    "from typing import Optional\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import time\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import random\n",
    "from torchmetrics import Accuracy, MetricCollection, Precision, Recall, ROC\n",
    "from torch import tensor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.profilers import PyTorchProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_color = '#E9BFC0'          #red\n",
    "val_df_color = '#C3D5E7'            #blue\n",
    "test_df_color = '#F4D98F'           #yellow\n",
    "threshold_color = '#DC96AE'         #pink\n",
    "\n",
    "real_line_color = '#93c47d'         #blue\n",
    "fake_line_color = '#E9BFC0'         #red\n",
    "maybe_line_color = '#F4D98F'        #yellow\n",
    "\n",
    "real_dot_color = '#56943a'          #green hard\n",
    "fake_dot_color = '#8a292c'          #red red\n",
    "maybe_dot_color = '#d69d00'         #yellow hard\n",
    "\n",
    "logreg_line_color = '#7db364'       #green\n",
    "logreg_fill_color = '#97c283'\n",
    "logreg_dot_color = '#48802e'\n",
    "\n",
    "binary_line_color = '#aeb1cf'       #purple\n",
    "binary_dot_color = '#8a8db6'\n",
    "binary_fill_color = '#bec0d8'       #3 tint lighter\n",
    "\n",
    "multiclass_line_color = '#a2c9ef'   #blue\n",
    "multiclass_fill_color = '#7a8c9f'\n",
    "multiclass_dot_color = '#1e456b' \n",
    "\n",
    "colors = ['#d1e5f0', '#94c4f3', '#63a7e0', '#358ece', '#0a6ab7', '#084f8a'] #blues for CM\n",
    "cmap = sns.color_palette(colors, as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()                                                         #lowercase   \n",
    "    text = re.sub(r\"@\\w*\", \" \", text)                                           #tags\n",
    "    text = re.sub(r\"#|^\\*|\\*$|&quot;|&gt;|&lt;|&lt;3\", \" \", text)               #special characters\n",
    "    text = text.replace(\"&amp;\", \" and \")                                       #&\n",
    "    text = re.sub(r\"ht+p+s?://\\S*\", \" \", text)                                  #links\n",
    "    text = re.sub(r\"[^a-zA-Z0-9æøåÆØÅ\\d\\s:/£$%€,-]|(?<!\\S)å(?!\\S)\", \"\", text)   #ascii\n",
    "    text = re.sub(r\",(?!\\d)\", \"\", text)                                         #comma\n",
    "    text = re.sub(r\"(\\S)\\.(\\S)\", r\"\\1. \\2\", text)                               #period\n",
    "    text = re.sub(r\"\\(\\)|\\[\\]|\\{\\}\", \" \", text)                                 #brackets\n",
    "    text = re.sub(r\"\\s[b-gjz]\\s\", \" \", text)                                    #single chars\n",
    "    text = \" \".join(text.split()).strip()                                       #spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSEED = 42\n",
    "seed_everything(RANDOMSEED, workers=True) #for dataloaders\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/thombras/files/NorLIAR_train_bin.csv')\n",
    "val_df = pd.read_csv('/home/thombras/files/NorLIAR_val_bin.csv')\n",
    "test_df = pd.read_csv('/home/thombras/files/NorLIAR_test_bin.csv')\n",
    "PFO_test_df = pd.read_csv('/home/thombras/files/PFO.csv')\n",
    "FND_test_df = pd.read_csv('/home/thombras/files/FND_gossip_df.csv')\n",
    "LABEL_COLUMNS = train_df.columns.tolist()[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['claim_no'] = train_df['claim_no'].apply(preprocess_text)\n",
    "val_df['claim_no'] = val_df['claim_no'].apply(preprocess_text)\n",
    "test_df['claim_no'] = test_df['claim_no'].apply(preprocess_text)\n",
    "PFO_test_df['claim_no'] = PFO_test_df['claim_no'].apply(preprocess_text)\n",
    "FND_test_df['claim_no'] = FND_test_df['claim_no'].apply(preprocess_text)\n",
    "test_df.shape, PFO_test_df.shape, FND_test_df.shape, LABEL_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norbert3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = 'ltg/norbert3-base' #LTG = Language Technology Group (University of Oslo)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "norbert3 = AutoModel.from_pretrained(BASE_MODEL, trust_remote_code=True, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_TOKEN_COUNT = 60\n",
    "N_EPOCHS = 20\n",
    "N_WORKERS = 2\n",
    "INPUT_SIZE = norbert3.config.hidden_size \n",
    "\n",
    "class data_encode(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, \n",
    "                tokenizer: AutoTokenizer, \n",
    "                MAX_TOKEN_COUNT: int = 128,\n",
    "                labels=None): \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = MAX_TOKEN_COUNT\n",
    "    \n",
    "    def __len__(self):                          \n",
    "        return len(self.data)                   \n",
    "    \n",
    "    def __getitem__(self, index: int):  \n",
    "        data_row = self.data.iloc[index]\n",
    "        text = data_row.claim_no\n",
    "        labels = data_row[LABEL_COLUMNS] \n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",                               #dynamic padding longest vs. max_length\n",
    "            truncation=True,\n",
    "            return_attention_mask=True, \n",
    "            return_tensors='pt', \n",
    "        )\n",
    "        return dict(\n",
    "            text=text,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),          #remove excess dim\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.FloatTensor(labels))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_encode(\n",
    "    train_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "val_dataset = data_encode(\n",
    "    val_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "test_dataset = data_encode(\n",
    "    test_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "PFO_test_dataset = data_encode(\n",
    "    PFO_test_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "FND_test_dataset = data_encode(\n",
    "    FND_test_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)\n",
    "PFO_test_loader = DataLoader(dataset=PFO_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)\n",
    "FND_test_loader = DataLoader(dataset=FND_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class NB3RegressorArch(pl.LightningModule):\n",
    "    def __init__(self, base_model, lr: Optional[float] = None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['base_model'])\n",
    "        self.bert = base_model\n",
    "        self.regressor_head = nn.Sequential(\n",
    "            nn.Linear(768, 1))\n",
    "        self.loss_func = nn.BCELoss()\n",
    "        self.LR = lr\n",
    "        self.acc = torchmetrics.classification.Accuracy(task='binary', average='weighted').cuda()\n",
    "        self.prec = torchmetrics.classification.Precision(task='binary', average='weighted').cuda()\n",
    "        self.rec = torchmetrics.classification.Recall(task='binary', average='weighted').cuda()\n",
    "        self.f1 = torchmetrics.classification.F1Score(task='binary', average='weighted').cuda()\n",
    "        self.auroc = torchmetrics.classification.AUROC(task='binary').cuda()\n",
    "        self.confusion_matrix = torchmetrics.classification.ConfusionMatrix(task='binary').cuda()\n",
    "        self.roc = torchmetrics.classification.ROC(task='binary').cuda()\n",
    "        self.val_y_prob = []\n",
    "        self.val_labels = []\n",
    "        self.test_y_prob = []\n",
    "        self.test_labels = []\n",
    "        self.writer = SummaryWriter(log_dir=\"/home/light_logs/log_reg\", filename_suffix='logreg_histo')\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooler = output.last_hidden_state[:, 0, :]  #CLS\n",
    "        pooler_numpy = pooler.detach().cpu().numpy()\n",
    "        self.writer.add_histogram('Pooler Output', pooler_numpy, self.global_step)\n",
    "        logits = self.regressor_head(pooler)\n",
    "        logits_numpy = logits.detach().cpu().numpy()\n",
    "        self.writer.add_histogram('Logits', logits_numpy, self.global_step)\n",
    "        y_prob = torch.sigmoid(logits)\n",
    "        y_prob_numpy = y_prob.detach().cpu().numpy()\n",
    "        self.writer.add_histogram('Probabilities', y_prob_numpy, self.global_step)\n",
    "        return logits, y_prob \n",
    "\n",
    "    def _recurrent_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        _, y_prob = self.forward(input_ids, attention_mask)\n",
    "        loss = self.loss_func(y_prob, labels)\n",
    "        return loss, labels, y_prob\n",
    "    \n",
    "    def _calculate_metrics(self, batch, batch_idx):\n",
    "        _, labels, y_prob = self._recurrent_step(batch, batch_idx)\n",
    "        acc = self.acc(y_prob, labels)\n",
    "        prec = self.prec(y_prob, labels)\n",
    "        rec = self.rec(y_prob, labels)\n",
    "        f1 = self.f1(y_prob, labels)\n",
    "        return acc, prec, rec, f1, y_prob    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, labels, _ = self._recurrent_step(batch, batch_idx)\n",
    "        acc, prec, rec, f1, y_prob = self._calculate_metrics(batch, batch_idx)\n",
    "        self.log_dict({'train_accuracy': acc, 'train_precision': prec, 'train_recall': rec, 'train_f1': f1},\n",
    "                prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "        self.log('train_loss', loss,  prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "        return {'loss': loss, 'prediction': y_prob, 'labels': labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, labels, y_prob = self._recurrent_step(batch, batch_idx)\n",
    "        acc, prec, rec, f1, y_prob = self._calculate_metrics(batch, batch_idx)\n",
    "        self.val_y_prob.append(y_prob)\n",
    "        self.val_labels.append(labels)\n",
    "        self.log_dict({'val_accuracy': acc, 'val_f1': f1},\n",
    "                prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "        self.log('val_loss', loss,  prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, labels, y_prob  = self._recurrent_step(batch, batch_idx)\n",
    "        acc, prec, rec, f1,  y_prob = self._calculate_metrics(batch, batch_idx)\n",
    "        self.test_y_prob.append(y_prob)\n",
    "        self.test_labels.append(labels)\n",
    "        self.log_dict({'test_accuracy': acc, 'test_precision': prec, 'test_recall': rec, 'test_f1': f1}, \n",
    "               prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_end(self):\n",
    "        self.writer.close()\n",
    "\n",
    "    def on_validation_end(self):\n",
    "        pass\n",
    "\n",
    "    def on_test_end(self):\n",
    "        test_y_prob_total = torch.cat(self.test_y_prob, dim=0)\n",
    "        test_labels_total = torch.cat(self.test_labels, dim=0).long()\n",
    "        print('test_y_prob_total\\n', test_y_prob_total)\n",
    "        print('test_labels_total\\n', test_labels_total)\n",
    "        \n",
    "        #ROC\n",
    "        self.roc.reset()\n",
    "        self.roc.update(test_y_prob_total, test_labels_total)\n",
    "        fpr, tpr, thresholds = self.roc.compute()\n",
    "        fpr_cpu = fpr.cpu().numpy()\n",
    "        tpr_cpu = tpr.cpu().numpy()\n",
    "        best_threshold_index = np.argmax(tpr_cpu - fpr_cpu)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(fpr_cpu, tpr_cpu, color=logreg_line_color, lw=2, label='ROC curve')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Reference Line')\n",
    "        plt.plot(fpr_cpu[best_threshold_index], tpr_cpu[best_threshold_index], 'o', color=logreg_dot_color, label=f'Best Threshold: {thresholds[best_threshold_index]:.2f}')\n",
    "        roc_treshold = thresholds[best_threshold_index]\n",
    "        plt.xlabel('False Positive Rate', fontsize=12)\n",
    "        plt.ylabel('True Positive Rate', fontsize=12)\n",
    "        plt.title('ROC for LR-NorBERT', fontsize=15)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        print(\"FPR, TPR\", fpr_cpu[best_threshold_index], tpr_cpu[best_threshold_index])\n",
    "        print(\"Best threshold index\", thresholds[best_threshold_index])\n",
    "        plt.show()\n",
    "\n",
    "        #AUROC\n",
    "        test_y_prob_total_np = test_y_prob_total.cpu().numpy() #gpu to cpu + tensor to array\n",
    "        test_labels_total_np = test_labels_total.cpu().numpy()\n",
    "        fpr, tpr, thresholds = roc_curve(test_labels_total_np, test_y_prob_total_np)\n",
    "        best_threshold = thresholds[np.argmax(tpr - fpr)]\n",
    "        auroc = roc_auc_score(test_labels_total_np, test_y_prob_total_np)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(fpr, tpr, color=logreg_line_color, lw=2, label='ROC curve')\n",
    "        plt.fill_between(fpr, tpr, color=logreg_fill_color, alpha=0.3)\n",
    "        plt.text(0.5, 0.5, f'AUROC = {auroc:.2f}', fontsize=13, ha='right', va='top')\n",
    "\n",
    "        plt.xlabel('False Positive Rate', fontsize=12)\n",
    "        plt.ylabel('True Positive Rate', fontsize=12)\n",
    "        plt.title('AUROC for LR-NorBERT', fontsize=15)\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.show()\n",
    "        print(\"AUROC value:\", auroc)\n",
    "\n",
    "        #CM\n",
    "        print('thresh', roc_treshold)\n",
    "        preds = (test_y_prob_total > roc_treshold).int()\n",
    "        self.confusion_matrix.reset()\n",
    "        test_end_cm = self.confusion_matrix(preds, test_labels_total)\n",
    "        test_end_cm_np = test_end_cm.cpu().numpy()\n",
    "        print(\"CM:\", test_end_cm)\n",
    "        \n",
    "        labels = np.array([\n",
    "            [f'True Negative\\n{test_end_cm_np[0][0]}', f'False Positive\\n{test_end_cm_np[0][1]}'],\n",
    "            [f'False Negative\\n{test_end_cm_np[1][0]}', f'True Positive\\n{test_end_cm_np[1][1]}']])\n",
    "\n",
    "        labels = np.asarray(labels).reshape(2, 2)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.heatmap(test_end_cm_np, annot=labels, cmap=cmap, fmt=\"\", annot_kws={\"size\": 13})\n",
    "        plt.ylabel(\"True Class\", fontsize=12)\n",
    "        plt.xlabel(\"Predicted Class\", fontsize=12)\n",
    "        plt.title(\"CM for LR-NorBERT\", fontsize=15)\n",
    "        plt.show()\n",
    "\n",
    "        test_y_prob_total_cpu = test_y_prob_total.cpu()\n",
    "        test_labels_total_cpu = test_labels_total.cpu()\n",
    "        print('best_threshold',best_threshold)\n",
    "        predictions = (test_y_prob_total_cpu > best_threshold).int()\n",
    "        target_names = ['Fake', 'Real']\n",
    "        print(classification_report(test_labels_total_cpu, predictions, target_names=target_names))\n",
    "        \n",
    "        self.test_y_prob = [] #reset the arrays before new test dataloader\n",
    "        self.test_labels = []\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.regressor_head.parameters(), lr=self.LR)\n",
    "        return optimizer\n",
    "\n",
    "class TrainingTime(Callback):\n",
    "    def on_train_start(self, trainer, NB3RegressorArch):\n",
    "        self.start = time.time()\n",
    "    \n",
    "    def on_train_end(self, trainer, NB3RegressorArch):\n",
    "        self.end = time.time()\n",
    "        total_minutes = (self.end-self.start)\n",
    "        print(f'\\nTraining finished: {total_minutes:.2f} seconds\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONITOR_METRIC = 'val_loss'\n",
    "MON_MODE = 'min'\n",
    "\n",
    "\n",
    "#hyperparameters\n",
    "TUNER_LR = 2.09e-6\n",
    "LR = TUNER_LR      \n",
    "DR = 0.2\n",
    "DEVICE = 'gpu'\n",
    "PATIENCE = 1\n",
    "TOP_K = 1\n",
    "DEV_RUN = 0\n",
    "\n",
    "TB_LOGGER = TensorBoardLogger('/home/light_logs',\n",
    "            name='lr')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath = '/home/checkpoints',\n",
    "  filename = 'best_lr',\n",
    "  save_top_k = TOP_K, \n",
    "  verbose = True,\n",
    "  monitor = MONITOR_METRIC,   \n",
    "  mode = MON_MODE)\n",
    "\n",
    "LR_MONITOR = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=MONITOR_METRIC, \n",
    "    patience=PATIENCE) \n",
    "\n",
    "nb3 = norbert3  #base model\n",
    "reg_model = NB3RegressorArch(\n",
    "    base_model=nb3,\n",
    "    lr=LR)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    fast_dev_run=DEV_RUN,\n",
    "    logger=TB_LOGGER,\n",
    "    min_epochs=1,\n",
    "    max_epochs=N_EPOCHS,\n",
    "    accelerator = DEVICE,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback, \n",
    "               TrainingTime(), LR_MONITOR]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nFast_dev_run =\", trainer.fast_dev_run)\n",
    "print(\"Max epoch:\", N_EPOCHS)\n",
    "print(\"Batch size:\", BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(reg_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(reg_model, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_version = '/home/checkpoints/best_lr.ckpt'\n",
    "trainer.test(ckpt_path=m_version, dataloaders=test_loader)\n",
    "#test_loader\n",
    "#PFO_test_loader\n",
    "#FND_test_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
