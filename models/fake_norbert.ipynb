{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import rcParams\n",
    "rcParams['text.usetex'] = True\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = ['Times New Roman']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from torchmetrics.functional import r2_score\n",
    "from torchmetrics import AUROC\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from torchmetrics import F1Score\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "from pytorch_lightning import Trainer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import F1Score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "import torchmetrics\n",
    "from torchmetrics import Metric\n",
    "import torchmetrics.classification\n",
    "import re\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from torchmetrics import Accuracy, MetricCollection, Precision, Recall, F1Score, Metric\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryConfusionMatrix\n",
    "from torch import tensor\n",
    "from typing import Optional\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import time\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from torchmetrics import Accuracy, MetricCollection, Precision, Recall, ROC\n",
    "from torch import tensor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from pytorch_lightning.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_color = '#E9BFC0'          #red\n",
    "val_df_color = '#C3D5E7'            #blue\n",
    "test_df_color = '#F4D98F'           #yellow\n",
    "threshold_color = '#DC96AE'         #pink\n",
    "\n",
    "real_line_color = '#93c47d'         #blue\n",
    "fake_line_color = '#E9BFC0'         #red\n",
    "maybe_line_color = '#F4D98F'        #yellow\n",
    "\n",
    "real_dot_color = '#56943a'          #green hard\n",
    "fake_dot_color = '#8a292c'          #red red\n",
    "maybe_dot_color = '#d69d00'         #yellow hard\n",
    "\n",
    "logreg_line_color = '#7db364'       #green\n",
    "logreg_fill_color = '#97c283'\n",
    "logreg_dot_color = '#48802e'\n",
    "\n",
    "binary_line_color = '#aeb1cf'       #purple\n",
    "binary_dot_color = '#8a8db6'\n",
    "binary_fill_color = '#bec0d8'       #3 tint lighter\n",
    "\n",
    "multiclass_line_color = '#a2c9ef'   #blue\n",
    "multiclass_fill_color = '#7a8c9f'\n",
    "multiclass_dot_color = '#1e456b' \n",
    "\n",
    "colors = ['#d1e5f0', '#94c4f3', '#63a7e0', '#358ece', '#0a6ab7', '#084f8a'] #blues for CM\n",
    "cmap = sns.color_palette(colors, as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"@\\w*\", \" \", text)                                           #tags\n",
    "    text = re.sub(r\"#|^\\*|\\*$|&quot;|&gt;|&lt;|&lt;3\", \" \", text)               #special characters\n",
    "    text = text.replace(\"&amp;\", \" and \")                                       #&\n",
    "    text = re.sub(r\"ht+p+s?://\\S*\", \" \", text)                                  #links\n",
    "    text = re.sub(r\"[^a-zA-Z0-9æøåÆØÅ\\d\\s:/£$%€,-]|(?<!\\S)å(?!\\S)\", \"\", text)   #ascii\n",
    "    text = re.sub(r\",(?!\\d)\", \"\", text)                                         #comma\n",
    "    text = re.sub(r\"(\\S)\\.(\\S)\", r\"\\1. \\2\", text)                               #period\n",
    "    text = re.sub(r\"\\(\\)|\\[\\]|\\{\\}\", \" \", text)                                 #brackets\n",
    "    text = re.sub(r\"\\s[b-gjz]\\s\", \" \", text)                                    #single chars\n",
    "    text = \" \".join(text.split()).strip()                                       #spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSEED = 42\n",
    "seed_everything(RANDOMSEED, workers=True) #for dataloaders\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/thombras/files/NorLIAR_train_bin.csv')\n",
    "val_df = pd.read_csv('/home/thombras/files/NorLIAR_val_bin.csv')\n",
    "test_df = pd.read_csv('/home/thombras/files/NorLIAR_test_bin.csv')\n",
    "PFO_test_df = pd.read_csv('/home/thombras/files/PFO.csv')\n",
    "FND_test_df = pd.read_csv('/home/thombras/files/FND_gossip_df.csv')\n",
    "LABEL_COLUMNS = train_df.columns.tolist()[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['claim_no'] = train_df['claim_no'].apply(preprocess_text)\n",
    "val_df['claim_no'] = val_df['claim_no'].apply(preprocess_text)\n",
    "test_df['claim_no'] = test_df['claim_no'].apply(preprocess_text)\n",
    "PFO_test_df['claim_no'] = PFO_test_df['claim_no'].apply(preprocess_text)\n",
    "FND_test_df['claim_no'] = FND_test_df['claim_no'].apply(preprocess_text)\n",
    "test_df.shape, PFO_test_df.shape, FND_test_df.shape, LABEL_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norbert3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = 'ltg/norbert3-base' #LTG = Language Technology Group (University of Oslo)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "norbert3 = AutoModel.from_pretrained(BASE_MODEL, trust_remote_code=True, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_TOKEN_COUNT = 60\n",
    "N_EPOCHS = 20\n",
    "N_WORKERS = 2\n",
    "INPUT_SIZE = norbert3.config.hidden_size \n",
    "\n",
    "class data_encode(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, \n",
    "                tokenizer: AutoTokenizer, \n",
    "                MAX_TOKEN_COUNT: int = 128,\n",
    "                labels=None): \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = MAX_TOKEN_COUNT\n",
    "    \n",
    "    def __len__(self):                  \n",
    "        return len(self.data)           \n",
    "    \n",
    "    def __getitem__(self, index: int):  \n",
    "        data_row = self.data.iloc[index]\n",
    "        text = data_row.claim_no\n",
    "        labels = data_row[LABEL_COLUMNS] \n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",  \n",
    "            truncation=True,\n",
    "            return_attention_mask=True, \n",
    "            return_tensors='pt', \n",
    "        )\n",
    "        return dict(\n",
    "            text=text,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),       \n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.FloatTensor(labels))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_encode(\n",
    "    train_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "val_dataset = data_encode(\n",
    "    val_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "test_dataset = data_encode(\n",
    "    test_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "PFO_test_dataset = data_encode(\n",
    "    PFO_test_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "FND_test_dataset = data_encode(\n",
    "    FND_test_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT,\n",
    "    LABEL_COLUMNS)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)\n",
    "PFO_test_loader = DataLoader(dataset=PFO_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)\n",
    "FND_test_loader = DataLoader(dataset=FND_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_df) // BATCH_SIZE  #binary floor division\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "WARMUP_STEPS = total_training_steps // 5\n",
    "TRAINING_STEPS = steps_per_epoch * N_EPOCHS - WARMUP_STEPS\n",
    "\n",
    "print('Epochs:{0:15}'.format(N_EPOCHS), '\\nBatch size:{0:12}'.format(BATCH_SIZE))\n",
    "print('-----------------------------')\n",
    "print('Dataset len:{0:13}'.format(len(train_dataset)))\n",
    "print('Steps per epoch:{0:8}'.format(steps_per_epoch))\n",
    "print('-----------------------------')\n",
    "print('Total training steps:{0:8}'.format(total_training_steps))\n",
    "print('Warmup is 1/5 of the total training steps:')\n",
    "print('- warmup steps:{0:8}'.format(WARMUP_STEPS), '\\n- training steps:{0:8}'.format(TRAINING_STEPS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class NB3BinaryArch(pl.LightningModule):              #https://torchmetrics.readthedocs.io/_/downloads/en/v0.7.1/pdf/\n",
    "   def __init__(self, base_model, \n",
    "      input_layer=768, fc1=512, fc2=256, fc3=64,\n",
    "      drop_rate=0.2, n_training_steps=None, n_warmup_steps=None, \n",
    "      lr=1e-5, wd=1e-2, eps=1e-8):\n",
    "      super().__init__()\n",
    "      self.drop_rate = drop_rate\n",
    "      self.N_WARMUP_STEPS = n_warmup_steps\n",
    "      self.N_TRAINING_STEPS = n_training_steps\n",
    "      self.LR = lr\n",
    "      self.WD = wd\n",
    "      self.EPS = eps\n",
    "      self.save_hyperparameters(ignore=['base_model']) #save params\n",
    "      self.bert = base_model\n",
    "      self.classification_head = nn.Sequential(\n",
    "         nn.Linear(input_layer, fc1), nn.ReLU(), nn.Dropout(self.drop_rate),\n",
    "         nn.Linear(fc1, fc2), nn.ReLU(), nn.Dropout(self.drop_rate),\n",
    "         nn.Linear(fc2, fc3), nn.ReLU(), nn.Dropout(self.drop_rate),\n",
    "         nn.Linear(fc3, 1))\n",
    "      self.loss_func = nn.BCELoss()\n",
    "      self.acc = torchmetrics.classification.Accuracy(task='binary', average='weighted').cuda()\n",
    "      self.prec = torchmetrics.classification.Precision(task='binary', average='weighted').cuda()\n",
    "      self.rec = torchmetrics.classification.Recall(task='binary', average='weighted').cuda()\n",
    "      self.f1 = torchmetrics.classification.F1Score(task='binary', average='weighted').cuda()\n",
    "      self.auroc = torchmetrics.classification.AUROC(task='binary').cuda()\n",
    "      self.confusion_matrix = torchmetrics.classification.ConfusionMatrix(task='binary').cuda()\n",
    "      self.roc = torchmetrics.classification.ROC(task='binary').cuda()\n",
    "      self.val_y_prob = [] \n",
    "      self.val_labels = []\n",
    "      self.test_y_prob = []\n",
    "      self.test_labels = []\n",
    "      self.writer = SummaryWriter(log_dir=\"/home/thombras/light_logs/binary\", filename_suffix='bin_histo')\n",
    "    \n",
    "   def forward(self, input_ids, attention_mask, labels=None):\n",
    "      output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "      pooler = output.last_hidden_state[:, 0, :] #CLS\n",
    "      pooler_numpy = pooler.detach().cpu().numpy()\n",
    "      self.writer.add_histogram('Pooler Output', pooler_numpy, self.global_step)\n",
    "      logits = self.classification_head(pooler)\n",
    "      logits_numpy = logits.detach().cpu().numpy()\n",
    "      self.writer.add_histogram('Logits', logits_numpy, self.global_step)\n",
    "      y_prob = torch.sigmoid(logits)\n",
    "      y_prob_numpy = y_prob.detach().cpu().numpy()\n",
    "      self.writer.add_histogram('Probabilities', y_prob_numpy, self.global_step) \n",
    "      return logits, y_prob\n",
    "\n",
    "   def _recurrent_step(self, batch, batch_idx):\n",
    "      input_ids = batch[\"input_ids\"]\n",
    "      attention_mask = batch[\"attention_mask\"]\n",
    "      labels = batch[\"labels\"]\n",
    "      logits, y_prob = self.forward(input_ids, attention_mask, labels=labels)\n",
    "      loss = self.loss_func(y_prob, labels)\n",
    "      return loss, logits, labels, y_prob\n",
    "   \n",
    "   def _calculate_metrics(self, batch, batch_idx):\n",
    "      loss, logits, labels, y_prob = self._recurrent_step(batch, batch_idx)\n",
    "      acc = self.acc(y_prob, labels)\n",
    "      prec = self.prec(y_prob, labels)\n",
    "      rec = self.rec(y_prob, labels)\n",
    "      f1 = self.f1(y_prob, labels)\n",
    "      return acc, prec, rec, f1\n",
    "\n",
    "   def training_step(self, batch, batch_idx):\n",
    "      loss, _, labels, y_prob = self._recurrent_step(batch, batch_idx)\n",
    "      acc, prec, rec, f1 = self._calculate_metrics(batch, batch_idx)\n",
    "      self.log_dict({'train_accuracy': acc, 'train_precision': prec, 'train_recall': rec, 'train_f1': f1},\n",
    "               prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "      self.log('train_loss', loss,  prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "      return {'loss': loss, 'prediction': y_prob, 'labels': labels}\n",
    "\n",
    "   def on_training_epoch_end(self):\n",
    "      pass\n",
    "\n",
    "   def on_train_end(self):\n",
    "      self.writer.close()\n",
    "\n",
    "   def validation_step(self, batch, batch_idx):\n",
    "      loss, _, labels, y_prob = self._recurrent_step(batch, batch_idx)\n",
    "      acc, prec, rec, f1 = self._calculate_metrics(batch, batch_idx)\n",
    "      self.val_y_prob.append(y_prob)\n",
    "      self.val_labels.append(labels)\n",
    "      self.log_dict({'val_accuracy': acc, 'val_f1': f1},\n",
    "               prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "      self.log('val_loss', loss,  prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "      return loss\n",
    "\n",
    "   def on_validation_epoch_end(self):\n",
    "      pass\n",
    "\n",
    "   def on_validation_end(self):\n",
    "      pass\n",
    "\n",
    "   def test_step(self, batch, batch_idx):\n",
    "      loss, _, labels, y_prob  = self._recurrent_step(batch, batch_idx)\n",
    "      acc, prec, rec, f1 = self._calculate_metrics(batch, batch_idx)\n",
    "      self.test_y_prob.append(y_prob)\n",
    "      self.test_labels.append(labels)\n",
    "      self.log_dict({'test_accuracy': acc, 'test_precision': prec, 'test_recall': rec, 'test_f1': f1},\n",
    "               prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "      self.log('test_loss', loss,  prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "      return loss\n",
    "\n",
    "   def on_test_end(self):\n",
    "      test_y_prob_total = torch.cat(self.test_y_prob, dim=0)\n",
    "      test_labels_total = torch.cat(self.test_labels, dim=0).long()\n",
    "      print('test_y_prob_total\\n', test_y_prob_total)\n",
    "      print('test_labels_total\\n', test_labels_total)\n",
    "      \n",
    "      #ROC\n",
    "      self.roc.reset()\n",
    "      self.roc.update(test_y_prob_total, test_labels_total)\n",
    "      fpr, tpr, thresholds = self.roc.compute()\n",
    "      fpr_cpu = fpr.cpu().numpy()\n",
    "      tpr_cpu = tpr.cpu().numpy()\n",
    "      best_threshold_index = np.argmax(tpr_cpu - fpr_cpu)\n",
    "      plt.figure(figsize=(8, 5))\n",
    "      plt.plot(fpr_cpu, tpr_cpu, color=binary_line_color, lw=2, label='ROC curve')\n",
    "      plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Reference Line')\n",
    "      plt.plot(fpr_cpu[best_threshold_index], tpr_cpu[best_threshold_index], 'o', color=binary_dot_color, label=f'Best Threshold: {thresholds[best_threshold_index]:.2f}')\n",
    "      roc_treshold = thresholds[best_threshold_index]\n",
    "      plt.xlabel('False Positive Rate', fontsize=12)\n",
    "      plt.ylabel('True Positive Rate', fontsize=12)\n",
    "      plt.title('ROC for Fake-NorBERT', fontsize=15)\n",
    "      plt.legend(loc=\"lower right\")\n",
    "      print(\"FPR, TPR\", fpr_cpu[best_threshold_index], tpr_cpu[best_threshold_index])\n",
    "      print(\"Best threshold index\", thresholds[best_threshold_index])\n",
    "      plt.show()\n",
    "\n",
    "      #AUROC\n",
    "      test_y_prob_total_np = test_y_prob_total.cpu().numpy() #GPU to CPU + Tensor to Array\n",
    "      test_labels_total_np = test_labels_total.cpu().numpy()\n",
    "      fpr, tpr, thresholds = roc_curve(test_labels_total_np, test_y_prob_total_np)\n",
    "      best_threshold = thresholds[np.argmax(tpr - fpr)]\n",
    "      auroc = roc_auc_score(test_labels_total_np, test_y_prob_total_np)\n",
    "      plt.figure(figsize=(8, 5))\n",
    "      plt.plot(fpr, tpr, color=binary_line_color, lw=2, label='ROC curve')\n",
    "      plt.fill_between(fpr, tpr, color=binary_fill_color, alpha=0.3) #shade the area under the curve\n",
    "      plt.text(0.5, 0.5, f'AUROC = {auroc:.2f}', fontsize=13, ha='right', va='top')\n",
    "\n",
    "      plt.xlabel('False Positive Rate', fontsize=12)\n",
    "      plt.ylabel('True Positive Rate', fontsize=12)\n",
    "      plt.title('AUROC for Fake-NorBERT', fontsize=15)\n",
    "      plt.legend(loc=\"upper left\")\n",
    "      plt.show()\n",
    "      print(\"AUROC value:\", auroc)\n",
    "\n",
    "      #CM\n",
    "      print('thresh', roc_treshold)\n",
    "      preds = (test_y_prob_total > roc_treshold).int()\n",
    "      self.confusion_matrix.reset()\n",
    "      test_end_cm = self.confusion_matrix(preds, test_labels_total)\n",
    "      test_end_cm_np = test_end_cm.cpu().numpy()\n",
    "      print(\"CM:\", test_end_cm)\n",
    "      \n",
    "      labels = np.array([\n",
    "         [f'True Negative\\n{test_end_cm_np[0][0]}', f'False Positive\\n{test_end_cm_np[0][1]}'],\n",
    "         [f'False Negative\\n{test_end_cm_np[1][0]}', f'True Positive\\n{test_end_cm_np[1][1]}']])\n",
    "\n",
    "      labels = np.asarray(labels).reshape(2, 2)\n",
    "      plt.figure(figsize=(8, 5))\n",
    "      sns.heatmap(test_end_cm_np, annot=labels, cmap=cmap, fmt=\"\", annot_kws={\"size\": 13})\n",
    "      plt.ylabel(\"True Class\", fontsize=12)\n",
    "      plt.xlabel(\"Predicted Class\", fontsize=12)\n",
    "      plt.title(\"CM for Fake-NorBERT\", fontsize=15)\n",
    "      plt.show()\n",
    "\n",
    "      test_y_prob_total_cpu = test_y_prob_total.cpu()\n",
    "      test_labels_total_cpu = test_labels_total.cpu()\n",
    "      print('best_threshold',best_threshold)\n",
    "      predictions = (test_y_prob_total_cpu > best_threshold).int()\n",
    "      target_names = ['Fake', 'Real']\n",
    "      print(classification_report(test_labels_total_cpu, predictions, target_names=target_names))\n",
    "\n",
    "      self.test_y_prob = []\n",
    "      self.test_labels = []\n",
    "\n",
    "   def configure_optimizers(self):\n",
    "      optimizer = torch.optim.AdamW(self.classification_head.parameters(), \n",
    "                        lr=self.LR, weight_decay=self.WD, eps=self.EPS)\n",
    "      scheduler = get_linear_schedule_with_warmup(\n",
    "         optimizer, \n",
    "         num_warmup_steps=self.N_WARMUP_STEPS, \n",
    "         num_training_steps=self.N_TRAINING_STEPS)\n",
    "      return dict(optimizer=optimizer, \n",
    "         lr_scheduler=dict(scheduler=scheduler, \n",
    "                           interval='step'))\n",
    "   \n",
    "class TrainingTime(Callback):\n",
    "    def on_train_start(self, trainer, NB3RegressorArch):\n",
    "        self.start = time.time()\n",
    "    \n",
    "    def on_train_end(self, trainer, NB3RegressorArch):\n",
    "        self.end = time.time()\n",
    "        total_minutes = (self.end-self.start)\n",
    "        print(f'\\nTraining finished: {total_minutes:.2f} seconds\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONITOR_METRIC = 'val_loss'\n",
    "MON_MODE = 'min'\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "FC1=1024\n",
    "FC2=768\n",
    "FC3=512\n",
    "TUNER_LR = 1.15e-5\n",
    "LR = TUNER_LR    \n",
    "WD = 1e-2\n",
    "EPS = 1e-8\n",
    "DR = 0.2\n",
    "DEVICE = 'gpu'\n",
    "PATIENCE = 1\n",
    "TOP_K = 1\n",
    "DEV_RUN = 0\n",
    "\n",
    "TB_LOGGER = TensorBoardLogger('/home/light_logs',\n",
    "            name='bin_nn')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath = '/home/checkpoints',\n",
    "  filename = 'best_binary',\n",
    "  save_top_k = TOP_K, \n",
    "  verbose = True,\n",
    "  monitor = MONITOR_METRIC,   \n",
    "  mode = MON_MODE)\n",
    "\n",
    "LR_MONITOR = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=MONITOR_METRIC, \n",
    "    patience=PATIENCE) \n",
    "\n",
    "nb3 = norbert3\n",
    "binary_model = NB3BinaryArch(\n",
    "    nb3,\n",
    "    input_layer=INPUT_SIZE,\n",
    "    fc1=FC1,\n",
    "    fc2=FC2,\n",
    "    fc3=FC3,\n",
    "    drop_rate=DR,\n",
    "    n_warmup_steps=WARMUP_STEPS,\n",
    "    n_training_steps=TRAINING_STEPS,\n",
    "    lr=LR,\n",
    "    wd=WD,\n",
    "    eps=EPS)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    fast_dev_run=DEV_RUN,\n",
    "    logger=TB_LOGGER,\n",
    "    min_epochs=1,\n",
    "    max_epochs=N_EPOCHS,\n",
    "    accelerator = DEVICE,\n",
    "    callbacks=[checkpoint_callback, \n",
    "               TrainingTime(), LR_MONITOR] \n",
    ")\n",
    "\n",
    "print(\"\\nFast_dev_run =\", trainer.fast_dev_run)\n",
    "print(\"Max epoch:\", N_EPOCHS)\n",
    "print(\"Batch size:\", BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(binary_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(binary_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_version = '/home/checkpoints/best_binary.ckpt'\n",
    "trainer.test(ckpt_path=m_version, dataloaders=test_loader)\n",
    "#test_loader\n",
    "#PFO_test_loader\n",
    "#FND_test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_version = '/home/checkpoints/best_binary.ckpt'\n",
    "Fake_NorBERT = NB3BinaryArch.load_from_checkpoint(checkpoint_path=m_version, base_model=norbert3)\n",
    "Fake_NorBERT.eval()\n",
    "Fake_NorBERT.freeze()\n",
    "THRESH = 0.45   #from roc\n",
    "MAX_TOKEN = 60\n",
    "\n",
    "class FakeNorBERT_predict:      \n",
    "    def __init__(self, model, tokenizer, max_token_len, threshold):\n",
    "        self.MODEL = model\n",
    "        self.TOKENIZER = tokenizer\n",
    "        self.DEVICE = torch.device('cuda')\n",
    "        self.MAX_TOKEN_LEN = max_token_len\n",
    "        self.THRESH = threshold\n",
    "\n",
    "    def calculate(self, text):\n",
    "        encode = self.TOKENIZER.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.MAX_TOKEN_LEN,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        input_ids = encode['input_ids'].to(self.DEVICE)\n",
    "        attention_mask = encode['attention_mask'].to(self.DEVICE)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.MODEL(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            unnormalized = outputs[0].item()\n",
    "            normalized = outputs[1].item()\n",
    "        return unnormalized, normalized\n",
    "\n",
    "    def score(self, text):\n",
    "        _, normalized = self.calculate(text)\n",
    "        print(round(normalized, 3))\n",
    "\n",
    "    def logit(self, text):\n",
    "        unnormalized, _ = self.calculate(text)\n",
    "        print(round(unnormalized, 3))\n",
    "\n",
    "    def predict(self, text):\n",
    "        _, normalized = self.calculate(text)\n",
    "        if normalized < self.THRESH:\n",
    "            print(\"Fake\")\n",
    "        else:\n",
    "            print(\"Real\")\n",
    "\n",
    "FNB = FakeNorBERT_predict(model=Fake_NorBERT, tokenizer=tokenizer, max_token_len=MAX_TOKEN, threshold=THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test = test_dataset[i]['text']\n",
    "FNB.score(test)\n",
    "FNB.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "tokenizer_pattern = r\"\\W+\"\n",
    "def shap_prediction(texts): #wrapper for shap\n",
    "    normalized_preds = []\n",
    "    for text in texts:\n",
    "        _, normalized = FNB.calculate(text)\n",
    "        normalized_preds.append(normalized)\n",
    "    return normalized_preds\n",
    "\n",
    "masker = shap.maskers.Text(tokenizer=tokenizer_pattern)\n",
    "explainer = shap.Explainer(shap_prediction, masker)\n",
    "shap_values = explainer([test])\n",
    "\n",
    "shap.plots.text(shap_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other visualisation plots\n",
    "shap.initjs()\n",
    "shap.plots.force(shap_values[0],plot_cmap=[real_dot_color,fake_dot_color])\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
