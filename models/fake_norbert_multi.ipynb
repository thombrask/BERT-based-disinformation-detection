{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['text.usetex'] = True\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = ['Times New Roman']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from torchmetrics import AUROC\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from torchmetrics import F1Score\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "from pytorch_lightning import Trainer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertTokenizerFast as AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import F1Score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "import torchmetrics\n",
    "from torchmetrics import Metric\n",
    "import torchmetrics.classification\n",
    "import re\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from torchmetrics import Accuracy, MetricCollection, Precision, Recall, F1Score, Metric\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryConfusionMatrix\n",
    "from torch import tensor\n",
    "from typing import Optional\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import time\n",
    "import io\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning import Trainer, seed_everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_color = '#E9BFC0'          #red\n",
    "val_df_color = '#C3D5E7'            #blue\n",
    "test_df_color = '#F4D98F'           #yellow\n",
    "threshold_color = '#DC96AE'         #pink\n",
    "\n",
    "real_line_color = '#93c47d'         #blue\n",
    "fake_line_color = '#E9BFC0'         #red\n",
    "maybe_line_color = '#F4D98F'        #yellow\n",
    "\n",
    "real_dot_color = '#56943a'          #green hard\n",
    "fake_dot_color = '#8a292c'          #red red\n",
    "maybe_dot_color = '#d69d00'         #yellow hard\n",
    "\n",
    "logreg_line_color = '#7db364'       #green\n",
    "logreg_fill_color = '#97c283'\n",
    "logreg_dot_color = '#48802e'\n",
    "\n",
    "binary_line_color = '#aeb1cf'       #purple\n",
    "binary_dot_color = '#8a8db6'\n",
    "binary_fill_color = '#bec0d8'       #3 tint lighter\n",
    "\n",
    "multiclass_line_color = '#a2c9ef'   #blue\n",
    "multiclass_fill_color = '#7a8c9f'\n",
    "multiclass_dot_color = '#1e456b' \n",
    "\n",
    "colors = ['#d1e5f0', '#94c4f3', '#63a7e0', '#358ece', '#0a6ab7', '#084f8a'] #blues for CM\n",
    "cmap = sns.color_palette(colors, as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"@\\w*\", \" \", text)                                           #tags\n",
    "    text = re.sub(r\"#|^\\*|\\*$|&quot;|&gt;|&lt;|&lt;3\", \" \", text)               #special characters\n",
    "    text = text.replace(\"&amp;\", \" and \")                                       #&\n",
    "    text = re.sub(r\"ht+p+s?://\\S*\", \" \", text)                                  #links\n",
    "    text = re.sub(r\"[^a-zA-Z0-9æøåÆØÅ\\d\\s:/£$%€,-]|(?<!\\S)å(?!\\S)\", \"\", text)   #ascii\n",
    "    text = re.sub(r\",(?!\\d)\", \"\", text)                                         #comma\n",
    "    text = re.sub(r\"(\\S)\\.(\\S)\", r\"\\1. \\2\", text)                               #period\n",
    "    text = re.sub(r\"\\(\\)|\\[\\]|\\{\\}\", \" \", text)                                 #brackets\n",
    "    text = re.sub(r\"\\s[b-gjz]\\s\", \" \", text)                                    #single chars\n",
    "    text = \" \".join(text.split()).strip()                                       #spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSEED = 42\n",
    "seed_everything(RANDOMSEED, workers=True) #for dataloaders\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/thombras/files/HUG_MULTI_LIAR/upsampled_train_df.csv')\n",
    "val_df = pd.read_csv('/home/thombras/files/HUG_MULTI_LIAR/val_with_labels.csv')\n",
    "test_df = pd.read_csv('/home/thombras/files/HUG_MULTI_LIAR/test_with_labels.csv')\n",
    "PFO_test_df = pd.read_csv('/home/thombras/files/PFO/PFO_3_test_df.csv')\n",
    "LABEL_COLUMNS_CLAS = train_df.columns.tolist()[15:] #fake, maybe, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['claim_no'] = train_df['claim_no'].apply(preprocess_text)\n",
    "val_df['claim_no'] = val_df['claim_no'].apply(preprocess_text)\n",
    "test_df['claim_no'] = test_df['claim_no'].apply(preprocess_text)\n",
    "PFO_test_df['claim_no'] = PFO_test_df['claim_no'].apply(preprocess_text)\n",
    "test_df.shape, PFO_test_df.shape, LABEL_COLUMNS_CLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### norbert3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = 'ltg/norbert3-base' #LTG = Language Technology Group (University of Oslo)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "norbert3 = AutoModel.from_pretrained(BASE_MODEL, trust_remote_code=True, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_TOKEN_COUNT = 60\n",
    "N_EPOCHS = 20\n",
    "N_WORKERS = 2\n",
    "INPUT_SIZE = norbert3.config.hidden_size \n",
    "\n",
    "class data_encode(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, \n",
    "                tokenizer: AutoTokenizer, \n",
    "                MAX_TOKEN_COUNT: int = 128,\n",
    "                labels=None): \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = MAX_TOKEN_COUNT\n",
    "    \n",
    "    def __len__(self):                 \n",
    "        return len(self.data)           \n",
    "    \n",
    "    def __getitem__(self, index: int):  \n",
    "        data_row = self.data.iloc[index]\n",
    "        text = data_row.claim_no\n",
    "        labels = data_row[LABEL_COLUMNS_CLAS] \n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\", \n",
    "            truncation=True,\n",
    "            return_attention_mask=True, \n",
    "            return_tensors='pt', \n",
    "        )\n",
    "        return dict(\n",
    "            text=text,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),       \n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.FloatTensor(labels))               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_encode(\n",
    "    train_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT)\n",
    "\n",
    "val_dataset = data_encode(\n",
    "    val_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT)\n",
    "\n",
    "test_dataset = data_encode(\n",
    "    test_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT)\n",
    "\n",
    "PFO_test_dataset = data_encode(\n",
    "    PFO_test_df,\n",
    "    tokenizer,\n",
    "    MAX_TOKEN_COUNT)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)\n",
    "PFO_test_loader = DataLoader(dataset=PFO_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=N_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_df) // BATCH_SIZE  \n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "WARMUP_STEPS = total_training_steps // 5\n",
    "TRAINING_STEPS = steps_per_epoch * N_EPOCHS - WARMUP_STEPS\n",
    "\n",
    "print('Epochs:{0:15}'.format(N_EPOCHS), '\\nBatch size:{0:12}'.format(BATCH_SIZE))\n",
    "print('-----------------------------')\n",
    "print('Dataset len:{0:13}'.format(len(train_dataset)))\n",
    "print('Steps per epoch:{0:8}'.format(steps_per_epoch))\n",
    "print('-----------------------------')\n",
    "print('Total training steps:{0:8}'.format(total_training_steps))\n",
    "print('Warmup is 1/5 of the total training steps:')\n",
    "print('- warmup steps:{0:8}'.format(WARMUP_STEPS), '\\n- training steps:{0:8}'.format(TRAINING_STEPS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteNorbertClassifierArch(pl.LightningModule):\n",
    "   def __init__(self, base_model, \n",
    "      input_layer=768, fc1=512, fc2=256, fc3=64, n_classes=3, \n",
    "      drop_rate=0.2, n_training_steps=None, n_warmup_steps=None, lr=1e-5, wd=1e-2, eps=1e-8):\n",
    "      super().__init__()\n",
    "      self.DROP_RATE = drop_rate\n",
    "      self.N_WARMUP_STEPS = n_warmup_steps\n",
    "      self.N_TRAINING_STEPS = n_training_steps\n",
    "      self.LR = lr\n",
    "      self.WD = wd\n",
    "      self.EPS = eps\n",
    "      self.save_hyperparameters(ignore=['base_model']) #save params\n",
    "      self.bert = base_model\n",
    "      self.classification_head = nn.Sequential(\n",
    "         nn.Linear(input_layer, fc1), nn.ReLU(), nn.Dropout(self.DROP_RATE), #fc1\n",
    "         nn.Linear(fc1, fc2), nn.ReLU(), nn.Dropout(self.DROP_RATE),         #fc2 \n",
    "         nn.Linear(fc2, fc3), nn.ReLU(), nn.Dropout(self.DROP_RATE),         #fc3   \n",
    "         nn.Linear(fc3, n_classes))\n",
    "      self.loss_func = nn.CrossEntropyLoss()\n",
    "      self.accuracy = torchmetrics.classification.Accuracy(task='multiclass', num_classes=n_classes, average='weighted').cuda()\n",
    "      self.precision = torchmetrics.classification.Precision(task='multiclass', num_classes=n_classes, average='weighted').cuda()\n",
    "      self.recall = torchmetrics.classification.Recall(task='multiclass', num_classes=n_classes, average='weighted').cuda()\n",
    "      self.f1_score = torchmetrics.classification.F1Score(task='multiclass', num_classes=n_classes, average='weighted').cuda()\n",
    "      self.confusion_matrix = torchmetrics.classification.MulticlassConfusionMatrix(num_classes=n_classes).cuda()\n",
    "      self.roc = torchmetrics.classification.ROC(task='multiclass', num_classes=n_classes).cuda()\n",
    "      self.train_y_prob = []\n",
    "      self.train_labels = []\n",
    "      self.test_y_prob = []\n",
    "      self.test_labels = []\n",
    "\n",
    "   def forward(self, input_ids, attention_mask, labels=None):\n",
    "      output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "      pooler = output.last_hidden_state[:, 0, :]   #CLS\n",
    "      logits = self.classification_head(pooler)\n",
    "      return logits\n",
    "\n",
    "   def _recurrent_step(self, batch, batch_idx):\n",
    "      input_ids = batch[\"input_ids\"]\n",
    "      attention_mask = batch[\"attention_mask\"]\n",
    "      labels = batch[\"labels\"]\n",
    "      logits = self.forward(input_ids, attention_mask, labels=labels)\n",
    "      y_prob = torch.softmax(logits, dim=1)\n",
    "      loss = 0\n",
    "      if labels is not None: \n",
    "         loss = self.loss_func(logits, labels)\n",
    "      return loss, logits, labels, y_prob\n",
    "\n",
    "   def _calculate_metrics(self, batch, batch_idx):\n",
    "         _, _, labels, y_prob = self._recurrent_step(batch, batch_idx)\n",
    "         pred = y_prob.argmax(dim=1)\n",
    "         label_arg = labels.argmax(dim=1)\n",
    "         acc = self.accuracy(pred, label_arg)\n",
    "         prec = self.precision(pred, label_arg)\n",
    "         rec = self.recall(pred, label_arg)\n",
    "         f1 = self.f1_score(pred, label_arg)\n",
    "         return acc, prec, rec, f1\n",
    "\n",
    "   def training_step(self, batch, batch_idx):\n",
    "      loss, logits, labels, y_prob = self._recurrent_step(batch, batch_idx)\n",
    "      acc, prec, rec, f1 = self._calculate_metrics(batch, batch_idx)\n",
    "      self.log_dict({'train_accuracy': acc, 'train_precision': prec,\n",
    "                     'train_recall': rec, 'train_f1': f1}, \n",
    "            logger=True, on_step=True, on_epoch=True, prog_bar=False)\n",
    "      \n",
    "      self.train_y_prob.append(y_prob)\n",
    "      self.train_labels.append(labels)\n",
    "      self.log('train_loss', loss, prog_bar=True, on_epoch=True, on_step=True)\n",
    "      return {'loss': loss, 'predictions': y_prob, 'labels': labels}\n",
    "\n",
    "   def configure_optimizers(self):\n",
    "      optimizer = AdamW(self.parameters(), lr=self.LR, weight_decay=self.WD, eps=self.EPS)\n",
    "      scheduler = get_linear_schedule_with_warmup(\n",
    "         optimizer, \n",
    "         num_warmup_steps=self.N_WARMUP_STEPS, \n",
    "         num_training_steps=self.N_TRAINING_STEPS)\n",
    "      return dict(optimizer=optimizer, \n",
    "         lr_scheduler=dict(scheduler=scheduler, \n",
    "                           interval='step'))\n",
    "   \n",
    "   def on_training_epoch_end(self, batch, batch_idx):\n",
    "     pass\n",
    "\n",
    "   def validation_step(self, batch, batch_idx):\n",
    "      loss, logits, labels, y_prob = self._recurrent_step(batch, batch_idx)\n",
    "      acc, prec, rec, f1 = self._calculate_metrics(batch, batch_idx)\n",
    "      self.log_dict({'val_accuracy': acc, 'val_f1': f1},\n",
    "                  prog_bar=False, logger=True, on_step=False, on_epoch=True)\n",
    "      self.log('val_loss', loss,  prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "      return loss\n",
    "\n",
    "   def test_step(self, batch, batch_idx):\n",
    "      loss, logits, labels, y_prob = self._recurrent_step(batch, batch_idx)\n",
    "      acc, prec, rec, f1 = self._calculate_metrics(batch, batch_idx)\n",
    "      self.log_dict({'test_accuracy': acc, 'test_precision': prec, 'test_recall': rec, 'test_f1': f1},\n",
    "               prog_bar=False, logger=True, on_step=True, on_epoch=True)\n",
    "      self.test_y_prob.append(y_prob)\n",
    "      self.test_labels.append(labels)\n",
    "      self.log('test_loss', loss,  prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "      return loss\n",
    "\n",
    "   def on_train_end(self):\n",
    "      pass\n",
    "\n",
    "   def on_test_end(self):\n",
    "      test_y_prob_total = torch.cat(self.test_y_prob, dim=0)\n",
    "      test_labels_total = torch.cat(self.test_labels, dim=0).long()\n",
    "      \n",
    "      print('test_y_prob_total', test_y_prob_total)\n",
    "      print('test_labels_total', test_labels_total)\n",
    "\n",
    "      #ROC\n",
    "      plt.figure(figsize=(8, 5))\n",
    "      colors = [fake_line_color, maybe_line_color, real_line_color] \n",
    "      class_labels = [\"Fake\", \"Maybe\", \"Real\"]  #\n",
    "      dot_colors = [fake_dot_color, maybe_dot_color, real_dot_color]\n",
    "\n",
    "      y_prob_cpu = test_y_prob_total.cpu().detach().numpy()\n",
    "      target_cpu = test_labels_total.cpu().detach().numpy()\n",
    "      n_classes = y_prob_cpu.shape[1]\n",
    "      best_thresholds = []\n",
    "      fpr = []\n",
    "      tpr = []\n",
    "      thresholds = []\n",
    "\n",
    "      for i in range(n_classes):\n",
    "         fpr, tpr, thresholds = roc_curve(target_cpu[:, i], y_prob_cpu[:, i])\n",
    "         roc_auc = auc(fpr, tpr)\n",
    "         print('roc_auc', roc_auc)\n",
    "         best_threshold_index = np.argmax(tpr - fpr)\n",
    "         best_threshold = thresholds[best_threshold_index]      #get best threshold for the current class\n",
    "         best_thresholds.append(best_threshold)                 #store best threshold\n",
    "         plt.plot(fpr, tpr, lw=2, color=colors[i], label='ROC curve')\n",
    "         plt.plot(fpr[best_threshold_index], tpr[best_threshold_index], 'o', color=dot_colors[i], label=f'Best Threshold: {thresholds[best_threshold_index]:.2f}')\n",
    "\n",
    "      plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Reference Line')\n",
    "      plt.xlim([0.0, 1.0])\n",
    "      plt.ylim([0.0, 1.05])\n",
    "      plt.xlabel('False Positive Rate', fontsize=12)\n",
    "      plt.ylabel('True Positive Rate', fontsize=12)\n",
    "      plt.title('ROC for Fake-NorBERT-multi', fontsize=15)\n",
    "      plt.legend(loc=\"lower right\")\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "\n",
    "      #Mean AUROC\n",
    "      all_fpr = np.linspace(0, 1, 100)\n",
    "      mean_tpr = 0.0\n",
    "      mean_auc = 0.0\n",
    "      for i in range(y_prob_cpu.shape[1]):\n",
    "         fpr, tpr, _ = roc_curve(target_cpu[:, i], y_prob_cpu[:, i])\n",
    "         mean_tpr += np.interp(all_fpr, fpr, tpr)\n",
    "\n",
    "      mean_tpr /= y_prob_cpu.shape[1]\n",
    "      mean_auc = auc(all_fpr, mean_tpr)\n",
    "      plt.figure(figsize=(8, 5))\n",
    "      plt.plot(all_fpr, mean_tpr, lw=2, color=multiclass_line_color, linestyle='--', label='ROC curve')\n",
    "      plt.fill_between(all_fpr, mean_tpr, color=multiclass_fill_color, alpha=0.3)\n",
    "      plt.text(0.5, 0.5, f'AUROC = {mean_auc:.2f}', fontsize=13, ha='right', va='top')\n",
    "      plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Reference Line')\n",
    "      plt.xlim([0.0, 1.0])\n",
    "      plt.ylim([0.0, 1.05])\n",
    "      plt.xlabel('False Positive Rate', fontsize=12)\n",
    "      plt.ylabel('True Positive Rate', fontsize=12)\n",
    "      plt.title('ROC for Fake-NorBERT-multi', fontsize=15)\n",
    "      plt.legend(loc=\"upper left\")\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "\n",
    "      #CM\n",
    "      predicted_classes = test_y_prob_total.argmax(dim=1)\n",
    "      y_truth = test_labels_total.argmax(dim=1)\n",
    "      predicted_classes_cpu = predicted_classes.cpu().numpy()\n",
    "      y_truth_cpu = y_truth.cpu().numpy()\n",
    "      conf_matrix = confusion_matrix(y_truth_cpu, predicted_classes_cpu)\n",
    "      labels = np.array([\n",
    "         [f'True Fake\\n{conf_matrix[0][0]}', f'False Maybe\\n{conf_matrix[0][1]}', f'False Real\\n{conf_matrix[0][2]}'],\n",
    "         [f'False Fake\\n{conf_matrix[1][0]}', f'True Maybe\\n{conf_matrix[1][1]}', f'False Real\\n{conf_matrix[1][2]}'],\n",
    "         [f'False Fake\\n{conf_matrix[2][0]}', f'False Maybe\\n{conf_matrix[2][1]}', f'True Real\\n{conf_matrix[2][2]}']\n",
    "      ])\n",
    "      plt.figure(figsize=(8, 5))\n",
    "      sns.heatmap(conf_matrix, annot=labels, cmap=cmap, fmt=\"\", annot_kws={\"size\": 13}, cbar=False)\n",
    "      plt.ylabel(\"True Class\", fontsize=12)\n",
    "      plt.xlabel(\"Predicted Class\", fontsize=12)\n",
    "      plt.title(\"CM for Fake-NorBERT-multi\", fontsize=15)\n",
    "      plt.show()\n",
    "\n",
    "      #CLASSIFICATION REPORT\n",
    "      class_names = [\"Fake\", \"Maybe\", \"Real\"]\n",
    "      print(classification_report(y_truth_cpu, predicted_classes_cpu, target_names=class_names))\n",
    "\n",
    "      self.test_y_prob = [] #reset arrays\n",
    "      self.test_labels = []\n",
    "\n",
    "class TrainingTime(Callback):\n",
    "    def on_train_start(self, trainer, NB3RegressorArch):\n",
    "        self.start = time.time()\n",
    "    \n",
    "    def on_train_end(self, trainer, NB3RegressorArch):\n",
    "        self.end = time.time()\n",
    "        total_minutes = (self.end-self.start)\n",
    "        print(f'\\nTraining finished: {total_minutes:.2f} seconds\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONITOR_METRIC = 'val_loss'\n",
    "MON_MODE = 'min'\n",
    "\n",
    "FC1=1024\n",
    "FC2=768\n",
    "FC3=512\n",
    "\n",
    "TUNER_LR = 3.31e-5 \n",
    "LR = TUNER_LR   \n",
    "WD = 1e-2\n",
    "EPS = 1e-8\n",
    "DR = 0.8\n",
    "GC = 0\n",
    "DEVICE = 'gpu'\n",
    "PATIENCE = 1\n",
    "TOP_K = 1\n",
    "DEV_RUN = 0\n",
    "\n",
    "TB_LOGGER = TensorBoardLogger('/home/light_logs',\n",
    "            name='multi')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath = '/home/checkpoints',\n",
    "  filename = 'best_multic',\n",
    "  save_top_k = TOP_K, \n",
    "  verbose = True,\n",
    "  monitor = MONITOR_METRIC,   \n",
    "  mode = MON_MODE)\n",
    "\n",
    "LR_MONITOR = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=MONITOR_METRIC, \n",
    "    patience=PATIENCE) \n",
    "\n",
    "nb3 = norbert3\n",
    "clas_model = LiteNorbertClassifierArch(\n",
    "    nb3,\n",
    "    input_layer=INPUT_SIZE,\n",
    "    fc1=FC1,\n",
    "    fc2=FC2,\n",
    "    fc3=FC3,\n",
    "    drop_rate=DR,\n",
    "    n_warmup_steps=WARMUP_STEPS,\n",
    "    n_training_steps=TRAINING_STEPS,\n",
    "    lr=LR,\n",
    "    wd=WD,\n",
    "    eps=EPS)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    fast_dev_run=DEV_RUN,\n",
    "    logger=TB_LOGGER,\n",
    "    min_epochs=1,\n",
    "    max_epochs=N_EPOCHS,\n",
    "    accelerator = DEVICE,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback, \n",
    "               TrainingTime(), LR_MONITOR]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nFast_dev_run =\", trainer.fast_dev_run)\n",
    "print(\"Max epoch:\", N_EPOCHS)\n",
    "print(\"Batch size:\", BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(clas_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(clas_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_version = '/home/checkpoints/best_multi.ckpt'\n",
    "trainer.test(ckpt_path=m_version, dataloaders=test_loader)\n",
    "#test_loader\n",
    "#PFO_test_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
